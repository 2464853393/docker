---
kind: StatefulSet
apiVersion: apps/v1beta2
metadata:
  name: spark-slave
  labels:
    app: spark
    component: spark-slave
  annotations:
    hadoop/version: 2.7.3
    jdk/version: jdk1.8.0_161
    spark/version: 2.3.0
spec:
  replicas: 3
  selector:
    matchLabels:
      app: spark
      component: spark-slave
  template:
    metadata:
      labels:
        app: spark
        component: spark-slave
    spec:
      volumes:
      - name: hdfs-config
        configMap:
          name: hdfs-configmap
          defaultMode: 420 
      - name: rm-config
        configMap:
          name: resourcemanager-configmap
          defaultMode: 420
      - name: spark-config
        configMap:
          name: spark-configmap
          defaultMode: 420          
      containers:
      - name: spark-slave
        image: 10.221.163.21:5000/zhhray/hadoop-spark:2.3.0
        command:
        - "/bin/bash"
        - "/etc/spark-config/bootstrap.sh"
        env:
        - name: MY_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
        - name: web
          containerPort: 8081
          protocol: TCP
        volumeMounts:
        - name: hdfs-config
          mountPath: "/tmp/hadoop/hdfs"
        - name: rm-config
          mountPath: "/tmp/hadoop/resourcemanager"  
        - name: datadir
          mountPath: "/usr/local/hadoop/tmp" 
        - name: spark-config
          mountPath: "/tmp/spark"  
        terminationMessagePath: "/dev/termination-log"
        terminationMessagePolicy: File
        imagePullPolicy: IfNotPresent
      restartPolicy: Always
      ### podAntiAffinity 描述pod被调度的策略
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: spark
                  component: spark-slave
              topologyKey: kubernetes.io/hostname           
      schedulerName: default-scheduler
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 200Mi      
  serviceName: spark-slave-headless
  podManagementPolicy: Parallel
