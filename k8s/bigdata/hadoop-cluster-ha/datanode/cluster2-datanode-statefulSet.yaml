---
kind: StatefulSet
apiVersion: apps/v1beta2
metadata:
  name: cluster2-hdfs-datanode
  labels:
    app: hadoop
    component: hadoop-datanode
    cluster: cluster2
    hbase: hbase
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hadoop
      component: hadoop-datanode
      cluster: cluster2
      hbase: hbase
  template:
    metadata:
      labels:
        app: hadoop
        component: hadoop-datanode
        cluster: cluster2
        hbase: hbase
    spec:
      volumes:
      - name: hdfs-config
        configMap:
          name: cluster2-hdfs-configmap
          defaultMode: 420 
      - name: rm-config
        configMap:
          name: cluster2-rm-configmap
          defaultMode: 420
      containers:
      - name: cluster2-datanode
        image: 10.221.163.21:5000/hadoop-hh:1
        command:
        - "/bin/bash"
        - "/etc/hadoop-config/bootstrap.sh"
        - "-d"
        env:
        - name: MY_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
        - name: hdfs-client
          containerPort: 50010
          protocol: TCP
        - name: hdfs-ipc
          containerPort: 50020
          protocol: TCP
        - name: web-http
          containerPort: 50075
          protocol: TCP  
        - name: nm-ipc
          containerPort: 8040
          protocol: TCP   
        - name: nm-address
          containerPort: 8041
          protocol: TCP    
        - name: nm-webapp
          containerPort: 8042
          protocol: TCP
        - name: hbase
          containerPort: 60010
          protocol: TCP
        - name: spark
          containerPort: 7707
          protocol: TCP
        - name: hivemetastore
          containerPort: 9083
          protocol: TCP
        - name: hivejdbc
          containerPort: 10001
          protocol: TCP
        resources:
          limits:
            cpu: '1'
            memory: 1Gi
          requests:
            cpu: 40m
            memory: 512Mi
        volumeMounts:
        - name: hdfs-config
          mountPath: "/tmp/hadoop/hdfs"
        - name: rm-config
          mountPath: "/tmp/hadoop/resourcemanager"  
        - name: datadir
          mountPath: "/usr/local/hadoop/tmp"
        livenessProbe:
          exec:
            command:
            - "/bin/bash"
            - "/etc/hadoop-config/healthcheck-datanode.sh"
          initialDelaySeconds: 15
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          exec:
            command:
            - "/bin/bash"
            - "/etc/hadoop-config/healthcheck-datanode.sh"
          initialDelaySeconds: 15
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3  
        terminationMessagePath: "/dev/termination-log"
        terminationMessagePolicy: File
        imagePullPolicy: IfNotPresent
      restartPolicy: Always
      ### podAntiAffinity 描述pod被调度的策略
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: hadoop
                  component: hadoop-datanode
                  cluster: cluster2
                  hbase: hbase
              topologyKey: kubernetes.io/hostname           
      schedulerName: default-scheduler
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 1Gi      
  serviceName: cluster2-datanode-headless
  podManagementPolicy: Parallel
